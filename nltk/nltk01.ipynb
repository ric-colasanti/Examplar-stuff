{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd7db2b7-3d21-469b-8b00-7ad9a8161270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today given the weather and what you are running?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today given the weather and what you are running? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\"\n",
    "\n",
    "print(sent_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9371d810-a189-409a-880a-6e6ebba5fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mr. Smith , how are you doing today given the weather and what you are running ? The weather is great , and Python is awesome . The sky is pinkish-blue . You should n't eat cardboard . "
     ]
    }
   ],
   "source": [
    "word_list = word_tokenize(EXAMPLE_TEXT) \n",
    "for i in word_list:\n",
    "    print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "612d5fca-0599-4635-8a9c-55beb462d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80c9fd8e-f4f5-43da-bf32-b3a824d59c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yours  whom  should've  out  during  ourselves  be  on  the  herself  don't  y  some  those  down  weren't  ve  where  after  you  have  s  was  itself  who  doesn  doesn't  too  for  can  hasn  did  ours  over  mustn't  hadn't  then  haven  any  about  it's  this  wasn  my  nor  against  mustn  themselves  i  having  its  most  re  through  shan  yourselves  to  you'd  further  needn  you'll  your  above  by  couldn  what  d  all  when  which  isn't  below  just  with  won  wouldn  a  own  been  so  again  than  an  he  and  are  if  should  mightn't  mightn  doing  under  not  here  his  you're  of  once  her  were  don  these  only  does  didn  but  few  at  very  hers  they  same  ma  will  we  aren  isn  their  you've  him  that  yourself  aren't  himself  theirs  or  such  am  won't  do  both  me  until  off  wouldn't  needn't  because  into  before  ll  o  from  has  wasn't  them  shan't  there  while  each  that'll  myself  now  hasn't  t  how  haven't  had  she  as  in  more  between  no  up  she's  weren  m  why  being  shouldn't  is  didn't  it  couldn't  hadn  shouldn  our  ain  other  "
     ]
    }
   ],
   "source": [
    "for word in stop_words:\n",
    "    print(word, end=\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc9f7992-9c7c-40ce-916a-847c796a5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = []\n",
    "\n",
    "for w in word_list:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdf1e2dd-d3a3-4808-bdb4-8287828ac0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello:hello\n",
      "Mr.:mr.\n",
      "Smith:smith\n",
      ",:,\n",
      "today:today\n",
      "given:given\n",
      "weather:weather\n",
      "running:run\n",
      "?:?\n",
      "The:the\n",
      "weather:weather\n",
      "great:great\n",
      ",:,\n",
      "Python:python\n",
      "awesome:awesom\n",
      ".:.\n",
      "The:the\n",
      "sky:sky\n",
      "pinkish-blue:pinkish-blu\n",
      ".:.\n",
      "You:you\n",
      "n't:n't\n",
      "eat:eat\n",
      "cardboard:cardboard\n",
      ".:.\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "for word in filtered_sentence:\n",
    "    print(word, end=\":\")\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdc65ea2-7a52-45ea-b01f-1e63d84ba486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello:Hello\n",
      "Mr.:Mr.\n",
      "Smith:Smith\n",
      ",:,\n",
      "today:today\n",
      "given:given\n",
      "weather:weather\n",
      "running:running\n",
      "?:?\n",
      "The:The\n",
      "weather:weather\n",
      "great:great\n",
      ",:,\n",
      "Python:Python\n",
      "awesome:awesome\n",
      ".:.\n",
      "The:The\n",
      "sky:sky\n",
      "pinkish-blue:pinkish-blue\n",
      ".:.\n",
      "You:You\n",
      "n't:n't\n",
      "eat:eat\n",
      "cardboard:cardboard\n",
      ".:.\n"
     ]
    }
   ],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "for word in filtered_sentence:\n",
    "    print(word, end=\":\")\n",
    "    print(lm.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772aefbf-07d4-46fa-8023-fb4bcd84e25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
